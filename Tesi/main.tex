% base
\documentclass{book}

% characters
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}

\usepackage{stmaryrd}
\SetSymbolFont{stmry}{bold}{U}{stmry}{m}{n}

% math
\usepackage{amsmath}
\usepackage{mathtools}

% graphics
\usepackage{mathdots}
\usepackage{nicematrix}
\setcounter{MaxMatrixCols}{20}
\usepackage{rotating}
\definecolor{lblue}{rgb}{.80, .90, .95}

\usepackage{color}
\definecolor{keywordcolor}{rgb}{0.7, 0.1, 0.1} % red
\definecolor{commentcolor}{rgb}{0.4, 0.4, 0.4} % grey
\definecolor{symbolcolor}{rgb}{0.0, 0.1, 0.6}  % blue
\definecolor{sortcolor}{rgb}{0.1, 0.5, 0.1}    % green

% font
% \usepackage{mathpazo}
% \usepackage{eulervm}
\usepackage{amsfonts}

% code
\usepackage{listings}
\def\lstlanguagefiles{lstlean.tex}
\lstset{language=lean}

% sections
\usepackage{emptypage}
\usepackage{titlesec}
\titleformat{\chapter}{\normalfont\huge\bfseries}{\thechapter.}{20pt}{\huge}

% theorems
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem*{definition*}{Definition}

\theoremstyle{remark}
\newtheorem{remark}{Remark}

\theoremstyle{plain}
\newtheorem{proposition}{Proposition}

% hyphenation
\usepackage{hyphenat}
\hyphenation{pri-mi-tive}

% macro
% \newcommand{\svdots}{\scriptscriptstyle \boldsymbol \vdots}
\newcommand{\perm}[1]{\scriptstyle \left\rmoustache #1 \right\rmoustache}
\newcommand{\bloch}[2]{\Block[draw=white,fill=lblue,line-width=.5mm,rounded-corners]{#1}{#2}} % https://en.wikipedia.org/wiki/Ernest_Bloch
\newcommand{\conv}[1]{\overbracket[.5pt][1pt]{\underbracket[.5pt][1pt]{#1}}}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\RPP}{\mathsf{RPP}}
\newcommand{\ORPP}{\mathsf{ORPP}}
\newcommand{\rppf}{\mathsf{f}}
\newcommand{\rppg}{\mathsf{g}}
\newcommand{\rpph}{\mathsf{h}}
\newcommand{\rppId}{\mathsf{Id}}
\newcommand{\rppNe}{\mathsf{Ne}}
\newcommand{\rppSu}{\mathsf{Su}}
\newcommand{\rppPr}{\mathsf{Pr}}
\newcommand{\rppSw}{\mathsf{Sw}}
\newcommand{\rppCo}{\fatsemi}
\newcommand{\rppPa}{\Vert}
\newcommand{\rppIt}[1]{\mathsf{It}[#1]}
\newcommand{\rppIf}[3]{\mathsf{If}[#1, #2, #3]}
\newcommand{\rppinc}{\mathsf{inc}}
\newcommand{\rppdec}{\mathsf{dec}}
\newcommand{\rppmul}{\mathsf{mul}}
\newcommand{\rppsquare}{\mathsf{square}}

% title
\title{A Formal Verification of Reversible Primitive Permutations}
\author{Giacomo Maletto}
\date{}

\begin{document}

\maketitle

\chapter{The definition}

\section{Reversible computing}

Reversible computing is a model of computation in which every process can be run backwards.
Simply put, in a reversible setting any program takes inputs and gives outputs (like usual), but can also go the other way around:
provided the output it can reconstruct the input.
In a mathematical sense, every function is expected to be invertible.

Why do we care about such a thing?

Firstly, having a programming language in which every function (or even a subset of functions) is reversible could lead to interesting and practical applications.

But we can also imagine reversible computers, in which the underlying architecture is inherently reversible:
Toffoli gates provides a way to do so.
The opposite of reversibility is loss of information, which (for thermodynamic reasons) leads to loss of energy and heat dissipation.
This means that a non-reversible gate dissipates energy each time information is discarded, while in principle a reversible computer wouldn't.

Lastly, reversible computing is directly related to quantum computing, as each operation in a quantum computer must be reversible.


\section{Reversible Primitive Permutations}

In the article I decided to formalize, the authors focus on providing a functional model of reversible computation.
They develop an inductively defined set of functions, called \textbf{Reversible Primitive Permutations} or \textbf{RPP},
which are expressive enough to represent all Primitive Recursive Functions (we talk about what this means in section ?).
Here is the definition that we will use:

\newpage

\begin{definition}[Reversible Primitive Permutations]
The class of \textbf{Reversible Primitive Permutations} or $\RPP$ is the smallest subset of functions $\Z^n \to \Z^n$ satisfying the following conditions:
\begin{itemize}

\item
The $n$-ary \textbf{identity} $\rppId_n (x_1, \dots, x_n) = (x_1, \dots, x_n)$ belongs to $\RPP$.
\[\begin{NiceMatrix}[nullify-dots]
  x_1    & \bloch{3-1}{\rppId_n} & x_1    \\
  \Vdots &                       & \Vdots \\
  x_n    &                       & x_n    \\
\end{NiceMatrix}\]
The meaning of these diagrams should be fairly obvious:
if the values on the left of a function are provided as inputs to that function, we get the values on the right as outputs.
\item
The \textbf{sign-change} $\rppNe (x) = -x$ belongs to $\RPP$.
\[\begin{NiceMatrix}
  x & \bloch{1-1}{\rppNe} & -x \\
\end{NiceMatrix}\]

\item
The \textbf{successor function} $\rppSu (x) = x+1$ belongs to $\RPP$.
\[\begin{NiceMatrix}
  x & \bloch{1-1}{\rppSu} & x+1 \\
\end{NiceMatrix}\]

\item
The \textbf{predecessor function} $\rppPr (x) = x-1$ belongs to $\RPP$.
\[\begin{NiceMatrix}
  x & \bloch{1-1}{\rppPr} & x-1 \\
\end{NiceMatrix}\]

\item
The \textbf{swap} $\rppSw (x, y) = (y, x)$ belongs to $\RPP$.
\[\begin{NiceMatrix}
  x & \bloch{2-1}{\rppSw} & y \\
  y &                     & x \\
\end{NiceMatrix}\]

\item
If $f : \Z^n \to \Z^n$ and $g : \Z^n \to \Z^n$ belongs to $\RPP$,
then the \textbf{series composition} $(f \rppCo g) : \Z^n \to \Z^n$ belongs to $\RPP$ and is such that:
\[(f \rppCo g) (x_1, \dots, x_n) = g (f (x_1, \dots, x_n)) = (g \circ f) (x_1, \dots, x_n).\]
We remark that $f \rppCo g$ means that $f$ is applied first, and then $g$, in opposition to the standard functional composition (denoted by $\circ$).
\[\begin{NiceMatrix}[nullify-dots]
  x_1    & \bloch{3-1}{f \rppCo g} & z_1    & \Block{3-1}{=} & x_1    & \bloch{3-1}{f} & y_1    & \bloch{3-1}{g} & z_1    \\
  \Vdots &                         & \Vdots &                & \Vdots &                & \Vdots &                & \Vdots \\
  x_n    &                         & z_n    &                & x_n    &                & y_n    &                & z_n    \\
\end{NiceMatrix}\]

\item

If $f : \Z^n \to \Z^n$ and $g : \Z^m \to \Z^m$ belongs to $\RPP$,
then the \textbf{parallel composition} $(f \rppPa g) : \Z^{n + m} \to \Z^{n + m} $ belongs to $\RPP$ and is such that:
\[(f \rppPa g) (x_1, \dots, x_n, y_1, \dots, y_m) = (f (x_1, \dots, x_n), g (y_1, \dots, y_m)).\]
\[\begin{NiceMatrix}[nullify-dots]
  x_1    & \bloch{6-1}{f \rppPa g} & w_1    & \Block{6-1}{=} & x_1    & \bloch{3-1}{f} & w_1    \\
  \Vdots &                         & \Vdots &                & \Vdots &                & \Vdots \\
  x_n    &                         & w_n    &                & x_n    &                & w_n    \\
  y_1    &                         & z_1    &                & y_1    & \bloch{3-1}{g} & z_1    \\
  \Vdots &                         & \Vdots &                & \Vdots &                & \Vdots \\
  y_m    &                         & z_m    &                & y_m    &                & z_m    \\
\end{NiceMatrix}\]

\item
If $f : \Z^n \to \Z^n$ belongs to $\RPP$,
then then \textbf{finite iteration} $\rppIt f : \Z^{n + 1} \to \Z^{n + 1}$ belongs to $\RPP$ and is such that:
\[ \rppIt f (x, x_1, \dots, x_n) = (x, (\overbrace{f \circ \dots \circ f}^{\downarrow x \text{ times}}) (x_1, \dots, x_n)) \]
where $\downarrow (\cdot) : \Z \to \N$ is defined as
\[\downarrow x = \begin{cases} x, & \text{if $x \ge 0$} \\
                               0, & \text{if $x < 0$} \end{cases}.\]
This means that the function $f$ is applied $\downarrow x$ times to $(x_1, \dots, x_n)$.
\[\begin{NiceMatrix}[nullify-dots]
  x      & \bloch{4-1}{\rppIt{f}} & x      & \Block{4-1}{=} & x      &                                                                       &                    &                & x      \\  
  x_1    &                        & y_1    &                & x_1    & \bloch{3-1}{f}                                                        & \Block{3-1}{\dots} & \bloch{3-1}{f} & y_1    \\
  \Vdots &                        & \Vdots &                & \Vdots &                                                                       &                    &                & \Vdots \\
  x_n    &                        & y_n    &                & x_n    &                                                                       &                    &                & y_n    \\
         &                        &        &                &        & \Block{1-3}{\underbrace{\hspace{5.5em}}_{\downarrow x \text{ times}}} &                    &                &        \\
\end{NiceMatrix}\]

\item
If $f, g, h : \Z^n \to \Z^n$ belongs to $\RPP$,
then the \textbf{selection} $\rppIf f g h : \Z^{n + 1} \to \Z^{n + 1}$ belongs to $\RPP$ and is such that:
\[\rppIf f g h (x, x_1, \dots, x_n) = \begin{cases} (x, f (x_1, \dots, x_n)), & \text{if $x > 0$} \\
                                                    (x, g (x_1, \dots, x_n)), & \text{if $x = 0$} \\
                                                    (x, h (x_1, \dots, x_n)), & \text{if $x < 0$} \end{cases}.\]
We remark that the argument $x$ which determines which among $f$, $g$ and $h$ must be used cannot be among the arguments of $f$, $g$ and $h$,
as that would break reversibility.
\[\begin{NiceMatrix}[nullify-dots]
  x      & \bloch{4-1}{\rppIf f g h} & x      &                &                     &                  \\
  x_1    &                           & y_1    & \Block{3-1}{=} & f (x_1, \dots, x_n) & \text{if } x > 0 \\
  \Vdots &                           & \Vdots &                & g (x_1, \dots, x_n) & \text{if } x = 0 \\
  x_n    &                           & y_n    &                & h (x_1, \dots, x_n) & \text{if } x < 0 \\
\CodeAfter
\SubMatrix\}{2-4}{4-4}\{
\end{NiceMatrix}\]

\end{itemize}
\end{definition}

\begin{remark}
If we have two functions of different arity, for example $f : \Z^3 \to \Z^3$ and $g : \Z^5 \to \Z^5$,
then we will still write $f \rppCo g$ to mean the function with arity $\max(3, 5)$ given by $(f \rppPa \rppId_2) \rppCo g$.
In general, the arity of the "smaller" function can be enlarged by a suitable parallel composition with the identity.
The same goes for the arguments of the selection $\rppIf f g h$.
\[\begin{NiceMatrix}[nullify-dots]
  x_1 & \bloch{5-1}{f \rppCo g} & z_1 & \Block{5-1}{=} & x_1 & \bloch{3-1}{f} & y_1 & \bloch{5-1}{g} & z_1 & \Block{5-1}{=} & x_1 & \bloch{3-1}{f}        & y_1 & \bloch{5-1}{g} & z_1 \\
  x_2 &                         & z_2 &                & x_2 &                & y_2 &                & z_2 &                & x_2 &                       & y_2 &                & z_2 \\
  x_3 &                         & z_3 &                & x_3 &                & y_3 &                & z_3 &                & x_3 &                       & y_3 &                & z_3 \\
  x_4 &                         & z_4 &                & x_4 &                & x_4 &                & z_4 &                & x_4 & \bloch{2-1}{\rppId_2} & x_4 &                & z_4 \\
  x_5 &                         & z_5 &                & x_5 &                & x_5 &                & z_5 &                & x_5 &                       & x_5 &                & z_5 \\
\end{NiceMatrix}\]
\end{remark}


\section{Some examples}

In order to get accustomed to this definition, let's see some examples.

\paragraph{Increment and decrement}
Let's try to imagine what addition should look like in $\RPP$.
Of course, addition is usually thought of as a function which takes two inputs and yields their sum:
something like $\texttt{add}(x,y) = x+y$.
But notice that this operation is not reversible:
given only the output (the value $x+y$) it is impossible to obtain the original values ($x, y$).
As we will see, every function in $\RPP$ is reversible, so it's impossible to define addition in this way.

Instead, we can define a function $\rppinc$ in $\RPP$ which, given $n \in \N$ and $x \in \Z$, yields
\[\begin{NiceMatrix}
  n & \bloch{2-1}{\rppinc} & n     \\
  x &                      & x + n \\
\end{NiceMatrix}\]
If $n$ is negative the output is just $(n, x)$.
The fact that the above diagram is only valid for $n \in \N$ might bother some of you;
we'll explain later why it is so, and how we can also make it work for $n \in \Z$.

For now let's focus on the output: we don't just have $x + n$ but also $n$, and indeed,
given both $n$ and $x+n$ we can reconstruct $n$ (obviously) and $x$ (by $(x+n)-n$).
As a matter of fact, the following function $\rppdec$ also belongs to $\RPP$:
\[\begin{NiceMatrix}
  n & \bloch{2-1}{\rppdec} & n     \\
  x &                      & x - n \\
\end{NiceMatrix}\]
and if we try to compose $\rppinc$ and $\rppdec$ we get this remarkable result:
\[\begin{NiceMatrix}
  n & \bloch{2-1}{\rppinc} & n     & \bloch{2-1}{\rppdec} & n \\
  x &                      & x + n &                      & x \\
\end{NiceMatrix}\]
and similarly for $\rppdec \rppCo \rppinc$.
So indeed $\rppdec$ is the inverse of $\rppinc$, and we can write $\rppdec = \rppinc^{-1}$.

But we haven't said how to actually define $\rppinc$.
Well, just like this:
\[\rppinc = \rppIt{\rppSu}\]
This means that we apply the successor function $\rppSu$ to the value $x$, for $\downarrow n$ times.
If $n \in \N$ then $\downarrow n = n$, so we effectively add $n$ to the value $x$.
If instead $n$ is negative then $\downarrow n = 0$ and nothing changes.

Can you guess how $\rppdec$ is defined?
\newpage
In a very similar manner, using the predecessor function:
\[\rppdec = \rppIt{\rppPr}\]
and as we will shortly see, finding the inverse is not something that we have to do by hand.

\paragraph{Multiplication and square}
We now turn our attention to multiplication.
The elementary-school way to define multiplication is by repeated addition, and we can define $\rppmul$ exactly like that:
\[\rppmul = \rppIt{\rppinc}.\]
As $\rppinc$ had arity $2$, $\rppmul$ has arity $2+1=3$.
If $n, m \in \N$ and $x \in \Z$ then we have
\[\begin{NiceMatrix}
  n & \bloch{3-1}{\rppmul} & n             \\
  m &                      & m             \\
  x &                      & x + n \cdot m \\
\end{NiceMatrix}\]
because we're essentially "incrementing by $m$" $n$ times;
so in this case we preserve both inputs and increase a certain variable $x$.

What is the inverse $\rppmul^{-1}$? Does it perform division?
Well, the truth is rather disappointing:
\[\begin{NiceMatrix}
  n & \bloch{3-1}{\rppmul^{-1}} & n             \\
  m &                           & m             \\
  x &                           & x - n \cdot m \\
\end{NiceMatrix}\]
We will see a way to calculate division in $\RPP$, but this is not it.

We're now ready to define the function $\rppsquare$ which is used to calculate the square of a number:
\[\rppsquare = (\rppId_1 \rppPa \rppSw) \rppCo \rppinc \rppCo \rppmul \rppCo \rppdec \rppCo (\rppId_1 \rppPa \rppSw).\]
That might look like a very complicated expression;
thankfully we can make use of diagrams to show what each step does.
Given $n \in \N$ and $x \in \Z$ we have
\[\begin{NiceMatrix}
  n &                     & n & \bloch{2-1}{\rppinc} & n & \bloch{3-1}{\rppmul} & n             & \bloch{2-1}{\rppdec} & n             &                     & n             \\
  x & \bloch{2-1}{\rppSw} & 0 &                      & n &                      & n             &                      & 0             & \bloch{2-1}{\rppSw} & x + n \cdot n \\
  0 &                     & x &                      & x &                      & x + n \cdot n &                      & x + n \cdot n &                     & 0             \\
\end{NiceMatrix}\]
so we add the result $n \cdot n$ to a variable $x$;
we also require an additional value initialized to 0.
We will make frequent use of variables initially set to 0 and which come back to 0 after the calculation;
these are traditionally called \textbf{ancillary arguments} or \textbf{ancillaes}, from the latin term used to describe female house slaves in ancient Rome.

You might be wondering what would happen if $n < 0$ or the ancilla was different from $0$.
The truth is, we don't really care.
We will often specify the behaviour of these functions given some initial values,
and we won't need to know what happens for different initial values because we'll never use those functions in other ways.

\section{Calculating the inverse}

Earlier we hinted at the fact that every function in $\RPP$ is invertible and the inverse belongs to $\RPP$;
furthermore, we don't need to perform the calculation manually, case by case.
In other words, there is an \textit{effective procedure} which produces the inverse $f^{-1} \in \RPP$ given any $f \in \RPP$.

\begin{proposition}[The inverse $f^{-1}$ of any $f$]
Let $f : \Z^n \to \Z^n$ belong to $\RPP$.
Then the inverse $f^{-1} : \Z^n \to \Z^n$ exists, belongs to $\RPP$ and, by definition, is
\begin{itemize}
\item $\rppId_n^{-1} = \rppId_n$
\item $\rppNe^{-1} = \rppNe$
\item $\rppSu^{-1} = \rppPr$
\item $\rppPr^{-1} = \rppSu$
\item $\rppSw^{-1} = \rppSw$
\item $(f \rppCo g)^{-1} = g^{-1} \rppCo f^{-1}$
\item $(f \rppPa g)^{-1} = f^{-1} \rppPa g^{-1}$
\item ${\rppIt f}^{-1} = \rppIt {f^{-1}}$
\item ${\rppIf f g h}^{-1} = \rppIf {f^{-1}} {g^{-1}} {h^{-1}}$
\end{itemize}
Then $f \rppCo f^{-1} = \rppId_n$ and $f^{-1} \rppCo f = \rppId_n$.
\end{proposition}
\begin{proof}
By induction on the definition of $f$.
\end{proof}

Well, that was rather succint.

We invite the reader to check that every listed inverse does indeed make sense;
for example, then function $\rppIt f (x, y_1, \dots, y_n)$ applies $\downarrow x$ times the function $f$ to the argument $(y_1, \dots, y_n)$.
If we want to "undo" this effect we just need to apply $\downarrow x$ times $f^{-1}$ to the same argument, so
${\rppIt f}^{-1} = \rppIt {f^{-1}}$.

Of course, that reasoning only works if in turn $f$ is also invertible and $f^{-1} \in \RPP$.
This is the reason that the proof is by induction:
given an arbitrary $\RPP$, if we unfold one step of the definition we get one of the cases listed.
We apply the appropriate step and then by inductive hypothesis we can assume that in turn its sub-terms are invertible.

Notice that in this way, if we try to calculate $\rppinc^{-1}$ we really do get $\rppdec$, as we had hoped for.

Since $\RPP$ is inductively defined, any proposition involving $\RPP$ functions can be proven using induction.
Not only that, but any function which has an argument $\RPP$ can be defined recursively,
and indeed we can also see $(\cdot)^{-1}:\RPP \to \RPP$ as a recursive function.
When we delve into type theory and the Lean theorem prover we will see that induction and recursion can be seen as really the same thing,
and it's just one of many similarities between functions and proofs.

\end{document}